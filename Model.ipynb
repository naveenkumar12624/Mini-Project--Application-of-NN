{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "063b8e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded opencv_face_detector.pbtxt\n",
      "Downloaded opencv_face_detector_uint8.pb\n",
      "Downloaded age_deploy.prototxt\n",
      "Downloaded age_net.caffemodel\n",
      "Downloaded gender_deploy.prototxt\n",
      "Downloaded gender_net.caffemodel\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/naveenkumar12624/Mini-Project_Age_and_Gender_Prediction/raw/main/opencv_face_detector.pbtxt\n",
    "!wget https://github.com/naveenkumar12624/Mini-Project_Age_and_Gender_Prediction/raw/main/opencv_face_detector_uint8.pb\n",
    "!wget https://github.com/naveenkumar12624/Mini-Project_Age_and_Gender_Prediction/raw/main/age_deploy.prototxt\n",
    "!wget https://github.com/naveenkumar12624/Mini-Project_Age_and_Gender_Prediction/raw/main/age_net.caffemodel\n",
    "!wget https://github.com/naveenkumar12624/Mini-Project_Age_and_Gender_Prediction/raw/main/gender_deploy.prototxt\n",
    "!wget https://github.com/naveenkumar12624/Mini-Project_Age_and_Gender_Prediction/raw/main/gender_net.caffemodel\n",
    "    \n",
    "    \n",
    "import requests\n",
    "\n",
    "urls = [\n",
    "    \"https://github.com/naveenkumar12624/Mini-Project_Age_and_Gender_Prediction/raw/main/opencv_face_detector.pbtxt\",\n",
    "    \"https://github.com/naveenkumar12624/Mini-Project_Age_and_Gender_Prediction/raw/main/opencv_face_detector_uint8.pb\",\n",
    "    \"https://github.com/naveenkumar12624/Mini-Project_Age_and_Gender_Prediction/raw/main/age_deploy.prototxt\",\n",
    "    \"https://github.com/naveenkumar12624/Mini-Project_Age_and_Gender_Prediction/raw/main/age_net.caffemodel\",\n",
    "    \"https://github.com/naveenkumar12624/Mini-Project_Age_and_Gender_Prediction/raw/main/gender_deploy.prototxt\",\n",
    "    \"https://github.com/naveenkumar12624/Mini-Project_Age_and_Gender_Prediction/raw/main/gender_net.caffemodel\"\n",
    "]\n",
    "\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"Downloaded {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4928e3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if files exist:\n",
      "Face Model Path Exists: True\n",
      "Face Proto Path Exists: True\n",
      "Age Model Path Exists: True\n",
      "Age Proto Path Exists: True\n",
      "Gender Model Path Exists: True\n",
      "Gender Proto Path Exists: True\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "No face detected\n",
      "Gender: Female\n",
      "Age: 25-32 years\n",
      "No face detected\n",
      "Gender: Female\n",
      "Age: 25-32 years\n",
      "Gender: Female\n",
      "Age: 0-2 years\n",
      "Gender: Female\n",
      "Age: 25-32 years\n",
      "Gender: Female\n",
      "Age: 25-32 years\n",
      "Gender: Female\n",
      "Age: 0-2 years\n",
      "Gender: Female\n",
      "Age: 38-43 years\n",
      "Gender: Male\n",
      "Age: 0-2 years\n",
      "Gender: Male\n",
      "Age: 38-43 years\n",
      "Gender: Male\n",
      "Age: 0-2 years\n",
      "Gender: Male\n",
      "Age: 38-43 years\n",
      "Gender: Female\n",
      "Age: 60-100 years\n",
      "Gender: Male\n",
      "Age: 48-53 years\n",
      "Gender: Female\n",
      "Age: 0-2 years\n",
      "Gender: Male\n",
      "Age: 38-43 years\n",
      "Gender: Male\n",
      "Age: 0-2 years\n",
      "Gender: Male\n",
      "Age: 48-53 years\n",
      "Gender: Female\n",
      "Age: 0-2 years\n",
      "Gender: Male\n",
      "Age: 38-43 years\n",
      "Gender: Female\n",
      "Age: 25-32 years\n",
      "Gender: Male\n",
      "Age: 48-53 years\n",
      "Gender: Female\n",
      "Age: 25-32 years\n",
      "Gender: Male\n",
      "Age: 48-53 years\n",
      "Gender: Female\n",
      "Age: 60-100 years\n",
      "Gender: Male\n",
      "Age: 38-43 years\n",
      "Gender: Female\n",
      "Age: 0-2 years\n",
      "Gender: Male\n",
      "Age: 48-53 years\n",
      "Gender: Female\n",
      "Age: 0-2 years\n",
      "Gender: Male\n",
      "Age: 48-53 years\n",
      "Gender: Female\n",
      "Age: 0-2 years\n",
      "Gender: Male\n",
      "Age: 48-53 years\n",
      "Gender: Female\n",
      "Age: 0-2 years\n",
      "Gender: Male\n",
      "Age: 38-43 years\n",
      "Gender: Female\n",
      "Age: 0-2 years\n",
      "Gender: Female\n",
      "Age: 25-32 years\n",
      "Gender: Female\n",
      "Age: 0-2 years\n",
      "Gender: Female\n",
      "Age: 38-43 years\n",
      "Gender: Female\n",
      "Age: 0-2 years\n",
      "Gender: Female\n",
      "Age: 0-2 years\n",
      "Gender: Female\n",
      "Age: 0-2 years\n",
      "Gender: Female\n",
      "Age: 25-32 years\n",
      "Gender: Female\n",
      "Age: 0-2 years\n",
      "Gender: Female\n",
      "Age: 0-2 years\n",
      "Gender: Female\n",
      "Age: 0-2 years\n",
      "Gender: Female\n",
      "Age: 25-32 years\n",
      "Gender: Female\n",
      "Age: 0-2 years\n",
      "Gender: Female\n",
      "Age: 0-2 years\n",
      "Gender: Female\n",
      "Age: 0-2 years\n",
      "Gender: Female\n",
      "Age: 0-2 years\n",
      "Gender: Female\n",
      "Age: 25-32 years\n",
      "Gender: Female\n",
      "Age: 25-32 years\n",
      "Gender: Female\n",
      "Age: 4-6 years\n",
      "Gender: Female\n",
      "Age: 0-2 years\n",
      "Gender: Female\n",
      "Age: 25-32 years\n",
      "Gender: Female\n",
      "Age: 0-2 years\n",
      "Gender: Female\n",
      "Age: 4-6 years\n",
      "Gender: Female\n",
      "Age: 4-6 years\n",
      "Gender: Female\n",
      "Age: 4-6 years\n",
      "Gender: Female\n",
      "Age: 60-100 years\n",
      "Gender: Female\n",
      "Age: 60-100 years\n",
      "Gender: Female\n",
      "Age: 60-100 years\n",
      "Gender: Female\n",
      "Age: 60-100 years\n",
      "Gender: Female\n",
      "Age: 8-12 years\n",
      "Gender: Female\n",
      "Age: 0-2 years\n",
      "Gender: Female\n",
      "Age: 0-2 years\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import math\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "def highlightFace(net, frame, conf_threshold=0.7):\n",
    "    frameOpencvDnn = frame.copy()\n",
    "    frameHeight = frameOpencvDnn.shape[0]\n",
    "    frameWidth = frameOpencvDnn.shape[1]\n",
    "    blob = cv2.dnn.blobFromImage(frameOpencvDnn, 1.0, (300, 300), [104, 117, 123], True, False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    faceBoxes = []\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > conf_threshold:\n",
    "            x1 = int(detections[0, 0, i, 3] * frameWidth)\n",
    "            y1 = int(detections[0, 0, i, 4] * frameHeight)\n",
    "            x2 = int(detections[0, 0, i, 5] * frameWidth)\n",
    "            y2 = int(detections[0, 0, i, 6] * frameHeight)\n",
    "            faceBoxes.append([x1, y1, x2, y2])\n",
    "            cv2.rectangle(frameOpencvDnn, (x1, y1), (x2, y2), (0, 255, 0), int(round(frameHeight / 150)), 8)\n",
    "    return frameOpencvDnn, faceBoxes\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--image', help=\"Path to image file. If not specified, webcam will be used\", default=None)\n",
    "\n",
    "    # Check if we are running in Jupyter or command line\n",
    "    if sys.argv[0].endswith('ipykernel_launcher.py'):\n",
    "        args = parser.parse_args(args=[])  # Bypass unrecognized arguments in Jupyter\n",
    "    else:\n",
    "        args = parser.parse_args()\n",
    "        \n",
    "\n",
    "    faceProto = \"opencv_face_detector.pbtxt\"\n",
    "    faceModel = \"opencv_face_detector_uint8.pb\"\n",
    "    ageProto = \"age_deploy.prototxt\"\n",
    "    ageModel = \"age_net.caffemodel\"\n",
    "    genderProto = \"gender_deploy.prototxt\"\n",
    "    genderModel = \"gender_net.caffemodel\"\n",
    "\n",
    "    print(\"Checking if files exist:\")\n",
    "    print(\"Face Model Path Exists:\", os.path.isfile(faceModel))\n",
    "    print(\"Face Proto Path Exists:\", os.path.isfile(faceProto))\n",
    "    print(\"Age Model Path Exists:\", os.path.isfile(ageModel))\n",
    "    print(\"Age Proto Path Exists:\", os.path.isfile(ageProto))\n",
    "    print(\"Gender Model Path Exists:\", os.path.isfile(genderModel))\n",
    "    print(\"Gender Proto Path Exists:\", os.path.isfile(genderProto))\n",
    "\n",
    "    MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "    ageList = ['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
    "    genderList = ['Male', 'Female']\n",
    "\n",
    "    # Load the models for face, age, and gender detection\n",
    "    faceNet = cv2.dnn.readNet(faceModel, faceProto)\n",
    "    ageNet = cv2.dnn.readNet(ageModel, ageProto)\n",
    "    genderNet = cv2.dnn.readNet(genderModel, genderProto)\n",
    "\n",
    "    # Capture video from file or webcam\n",
    "    video = cv2.VideoCapture(args.image if args.image else 0)\n",
    "    padding = 20\n",
    "\n",
    "    while cv2.waitKey(1) < 0:\n",
    "        hasFrame, frame = video.read()\n",
    "        if not hasFrame:\n",
    "            cv2.waitKey()\n",
    "            break\n",
    "\n",
    "        # Detect faces\n",
    "        resultImg, faceBoxes = highlightFace(faceNet, frame)\n",
    "        if not faceBoxes:\n",
    "            print(\"No face detected\")\n",
    "\n",
    "        # Loop over detected faces\n",
    "        for faceBox in faceBoxes:\n",
    "            face = frame[max(0, faceBox[1] - padding): min(faceBox[3] + padding, frame.shape[0] - 1),\n",
    "                         max(0, faceBox[0] - padding): min(faceBox[2] + padding, frame.shape[1] - 1)]\n",
    "\n",
    "            blob = cv2.dnn.blobFromImage(face, 1.0, (227, 227), MODEL_MEAN_VALUES, swapRB=False)\n",
    "\n",
    "            # Predict gender\n",
    "            genderNet.setInput(blob)\n",
    "            genderPreds = genderNet.forward()\n",
    "            gender = genderList[genderPreds[0].argmax()]\n",
    "            print(f'Gender: {gender}')\n",
    "\n",
    "            # Predict age\n",
    "            ageNet.setInput(blob)\n",
    "            agePreds = ageNet.forward()\n",
    "            age = ageList[agePreds[0].argmax()]\n",
    "            print(f'Age: {age[1:-1]} years')\n",
    "\n",
    "            # Display results on image\n",
    "            cv2.putText(resultImg, f'{gender}, {age}', (faceBox[0], faceBox[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "            cv2.imshow(\"Detecting age and gender\", resultImg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a9b7f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
